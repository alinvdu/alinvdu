## Welcome to my Github Page
<br />
<table>
  <tr>
    <td>
      <img src="https://github.com/alinvdu/alinvdu/assets/16021447/88a658aa-e4a6-4ea0-8d87-d9edac2d3511" width="80">
    </td>
    <td style="vertical-align:middle;">
      <strong>About me</strong>
    </td>
  </tr>
  <tr>
    <td></td>
    <td>
      <p>
        I'm an AI Engineer with extensive background in software engineering, now focusing on AI, cognitive psychology, neural signal processing, and domain-specific programming languages. My current work explores improving reasoning in AI and building projects with an interest in emotion in machines, blending technology with cognitive science.
</p>
    </td>
  </tr>
</table>
<br />
<table>
  <tr>
    <td>
      <img src="https://github.com/alinvdu/alinvdu/assets/16021447/18847f7a-adc8-4e98-8841-b22855d54bff" width="110">
    </td>
    <td style="vertical-align:middle;">
      <strong>Projects  </strong>
    </td>
  </tr>
  <tr>
    <td></td>
    <td>
      <p></p>
      <p><strong>Neural Art - Generating Art Images from Brain Signals</strong></p>
      <p>Generate art images similar to MidJourney directly from neural data (brain EEG) using an Emotiv Epoch X headset. This project is using Dream Diffusion to fine tune a Stable Diffusion model on EEG data and align it with CLIP (Demo here: https://www.youtube.com/watch?v=8v_EB73m6cQ)</p>
      <p>The project contains pre-processing stages for data curation & exposes model weights for a Stable Diffusion abstract art model with 5 days of training capable of generating art images similar to MidJourney from raw EEG data from an user exposed to image stimuli.</p>
    <p></p>
    </td>
  </tr>
  <tr>
    <td></td>
    <td>
      <p></p>
      <p><strong>Self AI - AI Platform for Mental Health Care</strong></p>
      <p>Self AI delivers real-time, low-latency interaction with a 3D virtual avatar fine-tuned for psychology. Built with FastAPI and WebRTC, it instantly transcribes spoken input, analyzes emotional tone, and taps into contextual memory via a Vector Database. A custom GPT model then generates psychologically-aware responses, streamed live with voice, expressions, and gestures. The system ensures data privacy, supports message retention, and can generate immersive background visuals.</p>
      <p>Live at https://selfai.live - Demo <a href="https://youtu.be/Z4px7rKjtIU?si=DJRBwX0wuB7iVHtx&t=83">here</a></p>
      <p>Explore it open-source. <a href="https://github.com/alinvdu/SelfInterface">SelfInterface</a> & <a href="https://github.com/alinvdu/SelfPersona">SelfPersona</a></p>
      <p></p>
    </td>
  </tr>
  <tr>
    <td></td>
    <td>
      <p></p>
      <p><strong>Zebra Fish connectome</strong></p>
      <p>Mapping zebra fish connectome in Python with custom 3D brain areas shapes: visualizations, connectivity matrix, conclusions about behavior modulation and sensory information. Check it out: https://github.com/alinvdu/neuromorphic-connectome-approach</p>
      <p></p>
    </td>
  </tr>
  <tr>
    <td></td>
    <td>
      <p></p>
      <p><strong>PDFToMem - Dynamic Memory Configuration using LlamaIndex & MCP</strong></p>
      <p>This project integrates some ideas I had regarding how to configure memory representations by using abstractions layers from LlamaIndex. It builds around multi-agent in which an Orchestrator decides between multiple agents that configure data structuring and representation using LangGraph. The memory representation is in form of LlamaIndex vector indices such as SentenceWindow, Semantic, Hierarchical, etc.
      </p>
      <p>This process is encapsulated by an MCP server which exposes tools for determining the representation, a storage FastAPI builds the query engine tools and then they can be consumed by the client. Learn more by watching the Demo!</p>
      <p>Watch video walkthrough <a href="https://www.youtube.com/watch?v=KzMl4TJMBNM">here</a></p>
      <p>Repository <a href="https://github.com/alinvdu/PdfToMem">here</a></p>
      <p></p>
    </td>
  </tr>
</table>
